{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# West Africa 1990-2021\n",
    "#### Download Observation data\n",
    "\n",
    "J.Joel & Dr.Olugboji  URSeismo   02/2022 modified from MTtime 1.1.0 (Accessible on Github: https://github.com/LLNL/mttime/tree/master/examples/notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy import read_events, UTCDateTime\n",
    "from obspy.clients.fdsn.mass_downloader import CircularDomain, Restrictions, MassDownloader\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: obspy\r\n",
      "Version: 1.2.2\r\n",
      "Summary: ObsPy - a Python framework for seismological observatories.\r\n",
      "Home-page: https://www.obspy.org\r\n",
      "Author: The ObsPy Development Team\r\n",
      "Author-email: devs@obspy.org\r\n",
      "License: GNU Lesser General Public License, Version 3 (LGPLv3)\r\n",
      "Location: /gpfs/fs2/scratch/tolugboj_lab/softwares/anaconda/anaconda3/2021.05/lib/python3.8/site-packages\r\n",
      "Requires: decorator, future, lxml, matplotlib, numpy, requests, scipy, setuptools, sqlalchemy\r\n",
      "Required-by: instaseis, mqs-reports, mttime\r\n"
     ]
    }
   ],
   "source": [
    "!pip show obspy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Catalog of event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_bool = True\n",
    "\n",
    "if event_bool:\n",
    "    dataCenter=\"IRIS\"\n",
    "    client = Client(dataCenter)\n",
    "    \n",
    "    starttime = UTCDateTime(\"1990-01-01T00:00:00\")\n",
    "    endtime = UTCDateTime(\"2021-12-31T23:59:59\")\n",
    "    \n",
    "    \n",
    "    catalog = client.get_events(starttime=starttime, endtime=endtime,\n",
    "                        minmagnitude=2.0,maxmagnitude=5.0,\n",
    "                        minlatitude=4.58, maxlatitude=24.78,\n",
    "                        minlongitude= -17.33, maxlongitude=23.98,\n",
    "                        includeallorigins=True)\n",
    "    \n",
    "   \n",
    "    \n",
    "    Path(quakemldir).mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "    #Write earthquakes catalog\n",
    "    catalog.write((\"%s/WafrQuakes90_21.xml\")%quakemldir,format=\"QUAKEML\") \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = read_events(\"quakes_xml/WafrQuakes90_21.xml\")\n",
    "for i, event in enumerate(catalog[1:]):\n",
    "    print(str(i) + \"_\" + str(event.origins[0].time))\n",
    "catalog.plot(projection=\"local\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download Observation data from IRIS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataCenter=\"IRIS\" \n",
    "\n",
    "# Time before and after event origin for waveform segments\n",
    "time_before = 5*60 #seconds\n",
    "time_after = 60*60 #seconds\n",
    "download_bool = True\n",
    "\n",
    "\n",
    "catalog = read_events(\"quakes_xml/WafrQuakes90_21.xml\")\n",
    "\n",
    "for event in catalog:\n",
    "    try:\n",
    "        evid = str(event.origins[0].time)\n",
    "        evid = evid[0:4] + evid[5:7] + evid[8:13] + evid[14:16] + evid[17:19]\n",
    "        evloc = event.event_descriptions[0].text\n",
    "        evid = evloc[:4] + evid\n",
    "        outdir = (\"data/events/%s\")%evid\n",
    "\n",
    "\n",
    "        Path(outdir).mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "\n",
    "        # Event origin\n",
    "        origin_time = event.preferred_origin().time\n",
    "        starttime = origin_time - time_before\n",
    "        endtime = origin_time + time_after\n",
    "\n",
    "        # Event location\n",
    "        evlo = event.preferred_origin().longitude\n",
    "        evla = event.preferred_origin().latitude\n",
    "        depth = event.preferred_origin().depth # in meters\n",
    "\n",
    "        # Set the search area\n",
    "        domain = CircularDomain(latitude=evla, longitude=evlo, minradius=0, maxradius=60)\n",
    "\n",
    "        # Set the search period and additional criteria\n",
    "        restrictions = Restrictions(starttime=starttime, endtime=endtime,\n",
    "            reject_channels_with_gaps=True,\n",
    "            minimum_length=0.95,\n",
    "            network=\"G,GE,II,KZ,XB,XJ,XK,DK,GT,IU,AF,4H,5H,6H,MN,BX,CM,PL,AC,CZ,KR,NR,RO,XW,NC,IU,NJ,AF,GH,XD\",\n",
    "            station=\"TAM,ABKT,ABKAR,PM29,PM34,PM35,LN46,B13NX,B14MH,ICESG,DBIC,KOWA,KUKU,SHAI,EDA,SOK,NAB1,NAB2,NAB3,NAB4,NAB5,NAB8,FAME,BANH,TUE,PM26,B01KR,B03SL,B15MW,Q04NM,Q06MQ,W04VR,GRTLG,RUS,MBAR,NIE,SACV,VLO,SVMA,MBO,DPC,BTK,NRN,TRKS,NE207,BUR31,KITG,LIRA,IRGVP,MSKU,BNG,TORO,KAD,WEIJ,BGCA,GOMA,FURI\",\n",
    "            channel_priorities=[\"BH[ZNE12]\"],                       \n",
    "            sanitize=True)\n",
    "\n",
    "        # Save catalog info to file\n",
    "        event_out = (\n",
    "            \"{evid:s},{origin:s},{jdate:s},\"\n",
    "            \"{lon:.4f},{lat:.4f},{depth:.4f},\"\n",
    "            \"{mag:.2f},{auth:s}\\n\"\n",
    "            )        \n",
    "\n",
    "        if event.preferred_magnitude() is None:\n",
    "            mag = -999.\n",
    "            magtype = \"ml\"\n",
    "        else:\n",
    "            mag = event.preferred_magnitude().mag\n",
    "            magtype = event.preferred_magnitude().magnitude_type\n",
    "        if event.preferred_origin().extra.catalog.value is None:\n",
    "            auth = \"unknown\"\n",
    "        else:\n",
    "            auth = event.preferred_origin().extra.catalog.value.replace(\" \",\"\")\n",
    "\n",
    "        event_out = event_out.format(\n",
    "            evid=evid,\n",
    "            origin=str(origin_time),\n",
    "            jdate=\"%s%s\"%(origin_time.year,origin_time.julday),\n",
    "            lon=evlo,\n",
    "            lat=evla,\n",
    "            depth=depth/1E3,\n",
    "            mag=mag,\n",
    "            auth=auth\n",
    "            )\n",
    "\n",
    "        outfile = (\"data/events/%s/datetime.csv\")%evid\n",
    "        with open(outfile,\"w\") as f:\n",
    "            f.write(\"evid,origin,jdate,lon,lat,depth,%s,auth\\n\"%magtype)\n",
    "            f.write(event_out)\n",
    "\n",
    "        # Dowanload waveforms and metadata\n",
    "        if download_bool:\n",
    "            mseed_storage = \"%s/waveforms\"%outdir\n",
    "            stationxml_storage = \"%s/stations\"%outdir\n",
    "            mdl = MassDownloader(providers=[dataCenter])\n",
    "            mdl_helper = mdl.download(domain, restrictions,\n",
    "                mseed_storage=mseed_storage,stationxml_storage=stationxml_storage)\n",
    "            print(\"%s download completed\"%outdir)\n",
    "\n",
    "\n",
    "        print(\"%s is DONE.\"%outdir)\n",
    "        \n",
    "    except Exception as e:\n",
    "                print(\"there was an exception %s\", str(e))\n",
    "                exception_type, exception_object, exception_traceback = sys.exc_info()\n",
    "                filename = exception_traceback.tb_frame.f_code.co_filename\n",
    "                line_number = exception_traceback.tb_lineno\n",
    "\n",
    "                print(\"Exception type: \", exception_type)\n",
    "                print(\"File name: \", filename)\n",
    "                print(\"Line number: \", line_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GE.ACRG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataCenter=\"http://geofon.gfz-potsdam.de\" \n",
    "\n",
    "# Time before and after event origin for waveform segments\n",
    "time_before = 5*60 #seconds\n",
    "time_after = 60*60 #seconds\n",
    "download_bool = True\n",
    "\n",
    "catalog = read_events(\"quakes_xml/WafrQuakes90_21.xml\")\n",
    "\n",
    "for event in catalog:\n",
    "    try:\n",
    "        evid = str(event.origins[0].time)\n",
    "        evid = evid[0:4] + evid[5:7] + evid[8:13] + evid[14:16] + evid[17:19]\n",
    "        evloc = event.event_descriptions[0].text\n",
    "        evid = evloc[:4] + evid\n",
    "        outdir = (\"data/events/%s\")%evid\n",
    "\n",
    "        Path(outdir).mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "\n",
    "        # Event origin\n",
    "        origin_time = event.preferred_origin().time\n",
    "        starttime = origin_time - time_before\n",
    "        endtime = origin_time + time_after\n",
    "\n",
    "        # Event location\n",
    "        evlo = event.preferred_origin().longitude\n",
    "        evla = event.preferred_origin().latitude\n",
    "        depth = event.preferred_origin().depth # in meters\n",
    "\n",
    "        # Set the search area\n",
    "        domain = CircularDomain(latitude=evla, longitude=evlo, minradius=0, maxradius=60)\n",
    "\n",
    "        # Set the search period and additional criteria\n",
    "        restrictions = Restrictions(starttime=starttime, endtime=endtime,\n",
    "            reject_channels_with_gaps=True,\n",
    "            minimum_length=0.95,\n",
    "            network=\"GE\",\n",
    "            station=\"ACRG\",\n",
    "            channel_priorities=[\"BH[ZNE12]\"],                       \n",
    "            sanitize=True)\n",
    "\n",
    "        # Save catalog info to file\n",
    "        event_out = (\n",
    "            \"{evid:s},{origin:s},{jdate:s},\"\n",
    "            \"{lon:.4f},{lat:.4f},{depth:.4f},\"\n",
    "            \"{mag:.2f},{auth:s}\\n\"\n",
    "            )        \n",
    "\n",
    "        if event.preferred_magnitude() is None:\n",
    "            mag = -999.\n",
    "            magtype = \"ml\"\n",
    "        else:\n",
    "            mag = event.preferred_magnitude().mag\n",
    "            magtype = event.preferred_magnitude().magnitude_type.lower()\n",
    "        if event.preferred_origin().extra.catalog.value is None:\n",
    "            auth = \"unknown\"\n",
    "        else:\n",
    "            auth = event.preferred_origin().extra.catalog.value.replace(\" \",\"\")\n",
    "\n",
    "        event_out = event_out.format(\n",
    "            evid=evid,\n",
    "            origin=str(origin_time),\n",
    "            jdate=\"%s%s\"%(origin_time.year,origin_time.julday),\n",
    "            lon=evlo,\n",
    "            lat=evla,\n",
    "            depth=depth/1E3,\n",
    "            mag=mag,\n",
    "            auth=auth\n",
    "            )\n",
    "        \n",
    "        # Dowanload waveforms and metadata\n",
    "        if download_bool:\n",
    "            mseed_storage = \"%s/waveforms\"%outdir\n",
    "            stationxml_storage = \"%s/stations\"%outdir\n",
    "            mdl = MassDownloader(providers=[dataCenter])\n",
    "            mdl_helper = mdl.download(domain, restrictions,\n",
    "                mseed_storage=mseed_storage,stationxml_storage=stationxml_storage)\n",
    "            print(\"%s download completed\"%outdir)\n",
    "\n",
    "\n",
    "        print(\"%s is DONE.\"%outdir)\n",
    "        \n",
    "    except Exception as e:\n",
    "                print(\"there was an exception %s\", str(e))\n",
    "                exception_type, exception_object, exception_traceback = sys.exc_info()\n",
    "                filename = exception_traceback.tb_frame.f_code.co_filename\n",
    "                line_number = exception_traceback.tb_lineno\n",
    "\n",
    "                print(\"Exception type: \", exception_type)\n",
    "                print(\"File name: \", filename)\n",
    "                print(\"Line number: \", line_number)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
